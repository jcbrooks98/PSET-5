knitr::opts_chunk$set(echo = TRUE)
#include relevant libraries for project
library(aplpack)
library(fpc)
library(cluster)
library(ape)
library(ggplot2)
library(DBItest)
library(tidyverse)
library(factoextra)
library(psych)
library(rela)
library(corrplot)
library(PerformanceAnalytics)
library(gridExtra)
library(NbClust)
PD <- read.csv("data.csv", header=TRUE, stringsAsFactors = FALSE)
#isolate only complete cases
PD <- PD[complete.cases(PD),]
#make sure data is numeric where it ought to be numeric (in the original dataset, for some reason some player heights/weights/etc [variables that need to be put in numeric terms], were read as characters [perhaps due to spaces or apostrophes])
PD[,4] <- as.numeric(PD[,4])
PD[,6] <- as.numeric(PD[,6])
PD[,7] <- as.numeric(PD[,7])
PD[,9] <- as.numeric(PD[,9])
PD[,17] <- as.numeric(PD[,17])
PD[,18] <- as.numeric(PD[,18])
summary(PD)
head(PD)
# Frequency Examinations for Categoricals
table(PD$Nationality)
table(PD$Club)
# Plot to give a sense of the variance in number of players produced by different countries
plot(table(PD$Nationality))
#summary histograms for all of the continuous variables using ggplot function
PD[c(4, 6, 7, 9, 11, 12, 13, 16:57)] %>%
gather(key="key",value="value") %>%
ggplot(aes(x=value))+
geom_density()+
facet_wrap(vars(key),scales="free")
#boxplots for some of the variables that did not have histograms that resembled an approximately normal distribution
boxplotCols <- c(9, 11, 13, 39, 4, 40, 57, 13)
# boxplotCols <- c(4, 6, 8) # use this to get a sense of plots when u don't want to load all plots
PDNames <- colnames(PD)
for (col in boxplotCols){
boxplot(PD[, col], main=PDNames[col])
}
# Correlation matrix shown in latter part
#subset data that we will use for factor analysis
data <- PD[,c(4, 6, 7, 9, 11, 12, 13, 16:57)]
#partition into thirds so that correlation plots are more readible
whole <- data[,1:length(data)]
data1 <- data[,1:length(data)/3]
data2 <- data[,(length(data)/3):(2*(length(data)/3))]
data3 <- data[,(2*(length(data)/3)):length(data)]
#compute the correlation matrix between all indicators
corrplot(cor(data1),method = "ellipse", order="hclust", tl.col = "black", tl.cex=.8)
corrplot(cor(data2),method = "ellipse", order="hclust", tl.col = "black", tl.cex=.8)
corrplot(cor(data3),method = "ellipse", order="hclust", tl.col = "black", tl.cex=.8)
#KMO
datamat <- data.matrix(whole)
output1 <- paf(datamat, eigcrit=1, convcrit=.001)
print(output1$KMO)
#summary(output1)
#Using PCA to help decide on a number of latent factors
fit <- princomp(whole, cor=FALSE)
#used two different metrics to determine how many latent factors we should use in our analyses
#eigenvalue > 1 to determine number of latent factors
print(summary(fit),digits=2,loadings=fit$loadings,cutoff=0)
#scree plot
plot(fit, type="lines", main="Scree Plot for Factor Analysis of FIFA Data",col="red",lwd=2,pch=19,cex=1.2)
fact_ml <- fa(datamat, nfactors = 3, rotate = "varimax", SMC = FALSE, fm="ml")
fact_ml <- fa(datamat, nfactors = 3, rotate = "varimax", fm="ml")
fact_ml <- fa(data, nfactors = 3, rotate = "varimax", fm="ml")
knitr::opts_chunk$set(echo = TRUE)
fact_ml <- fa(datamat, nfactors = 3, rotate = "varimax", fm="ml")
knitr::opts_chunk$set(echo = TRUE)
#include relevant libraries for project
library(aplpack)
library(fpc)
library(cluster)
library(ape)
library(ggplot2)
library(DBItest)
library(tidyverse)
library(factoextra)
library(psych)
library(rela)
library(corrplot)
library(PerformanceAnalytics)
library(gridExtra)
library(NbClust)
PD <- read.csv("data.csv", header=TRUE, stringsAsFactors = FALSE)
#isolate only complete cases
PD <- PD[complete.cases(PD),]
#make sure data is numeric where it ought to be numeric (in the original dataset, for some reason some player heights/weights/etc [variables that need to be put in numeric terms], were read as characters [perhaps due to spaces or apostrophes])
PD[,4] <- as.numeric(PD[,4])
PD[,6] <- as.numeric(PD[,6])
PD[,7] <- as.numeric(PD[,7])
PD[,9] <- as.numeric(PD[,9])
PD[,17] <- as.numeric(PD[,17])
PD[,18] <- as.numeric(PD[,18])
summary(PD)
head(PD)
# Frequency Examinations for Categoricals
table(PD$Nationality)
table(PD$Club)
# Plot to give a sense of the variance in number of players produced by different countries
plot(table(PD$Nationality))
#summary histograms for all of the continuous variables using ggplot function
PD[c(4, 6, 7, 9, 11, 12, 13, 16:57)] %>%
gather(key="key",value="value") %>%
ggplot(aes(x=value))+
geom_density()+
facet_wrap(vars(key),scales="free")
#boxplots for some of the variables that did not have histograms that resembled an approximately normal distribution
boxplotCols <- c(9, 11, 13, 39, 4, 40, 57, 13)
# boxplotCols <- c(4, 6, 8) # use this to get a sense of plots when u don't want to load all plots
PDNames <- colnames(PD)
for (col in boxplotCols){
boxplot(PD[, col], main=PDNames[col])
}
# Correlation matrix shown in latter part
#subset data that we will use for factor analysis
data <- PD[,c(4, 6, 7, 9, 11, 12, 13, 16:57)]
whole <- data[,1:length(data)]
data1 <- data[,1:length(data)/3]
data2 <- data[,(length(data)/3):(2*(length(data)/3))]
data3 <- data[,(2*(length(data)/3)):length(data)]
fact_ml <- fa(datamat, nfactors = 3, rotate = "varimax", fm="ml")
#KMO
datamat <- data.matrix(whole)
fact_ml <- fa(data, nfactors = 3, rotate = "varimax", fm="ml")
fact_ml <- fa(datamat, nfactors = 3, rotate = "varimax", fm="ml")
fact_ml <- fa(datamat, nfactors = 3, SMC = FALSE, rotate = "varimax", fm="ml")
knitr::opts_chunk$set(echo = TRUE)
#include relevant libraries for project
library(aplpack)
library(fpc)
library(cluster)
library(ape)
library(ggplot2)
library(DBItest)
library(tidyverse)
library(factoextra)
library(psych)
library(rela)
library(corrplot)
library(PerformanceAnalytics)
library(gridExtra)
library(NbClust)
PD <- read.csv("data.csv", header=TRUE, stringsAsFactors = FALSE)
#isolate only complete cases
PD <- PD[complete.cases(PD),]
#make sure data is numeric where it ought to be numeric (in the original dataset, for some reason some player heights/weights/etc [variables that need to be put in numeric terms], were read as characters [perhaps due to spaces or apostrophes])
PD[,4] <- as.numeric(PD[,4])
PD[,6] <- as.numeric(PD[,6])
PD[,7] <- as.numeric(PD[,7])
PD[,9] <- as.numeric(PD[,9])
PD[,17] <- as.numeric(PD[,17])
PD[,18] <- as.numeric(PD[,18])
summary(PD)
head(PD)
# Frequency Examinations for Categoricals
table(PD$Nationality)
table(PD$Club)
# Plot to give a sense of the variance in number of players produced by different countries
plot(table(PD$Nationality))
#summary histograms for all of the continuous variables using ggplot function
PD[c(4, 6, 7, 9, 11, 12, 13, 16:57)] %>%
gather(key="key",value="value") %>%
ggplot(aes(x=value))+
geom_density()+
facet_wrap(vars(key),scales="free")
#boxplots for some of the variables that did not have histograms that resembled an approximately normal distribution
boxplotCols <- c(9, 11, 13, 39, 4, 40, 57, 13)
# boxplotCols <- c(4, 6, 8) # use this to get a sense of plots when u don't want to load all plots
PDNames <- colnames(PD)
for (col in boxplotCols){
boxplot(PD[, col], main=PDNames[col])
}
# Correlation matrix shown in latter part
#subset data that we will use for factor analysis
data <- PD[,c(4, 6, 7, 9, 11, 12, 13, 16:57)]
#partition into thirds so that correlation plots are more readible
whole <- data[,1:length(data)]
data1 <- data[,1:length(data)/3]
data2 <- data[,(length(data)/3):(2*(length(data)/3))]
data3 <- data[,(2*(length(data)/3)):length(data)]
#compute the correlation matrix between all indicators
corrplot(cor(data1),method = "ellipse", order="hclust", tl.col = "black", tl.cex=.8)
corrplot(cor(data2),method = "ellipse", order="hclust", tl.col = "black", tl.cex=.8)
corrplot(cor(data3),method = "ellipse", order="hclust", tl.col = "black", tl.cex=.8)
#KMO
datamat <- data.matrix(whole)
output1 <- paf(datamat, eigcrit=1, convcrit=.001)
print(output1$KMO)
#summary(output1)
#Using PCA to help decide on a number of latent factors
fit <- princomp(whole, cor=FALSE)
#used two different metrics to determine how many latent factors we should use in our analyses
#eigenvalue > 1 to determine number of latent factors
print(summary(fit),digits=2,loadings=fit$loadings,cutoff=0)
#scree plot
plot(fit, type="lines", main="Scree Plot for Factor Analysis of FIFA Data",col="red",lwd=2,pch=19,cex=1.2)
fact_ml <- fa(datamat, nfactors = 3, SMC = FALSE, rotate = "varimax", fm="ml")
fact_ml$PVAL
#Loading plot for first two factors using Maximum Likelihood
plot(fact_ml$loadings, pch=18, col='red', main="ML Loading Plot for First Two Factors",xlab="1st Factor: Ball Control", ylab="2nd Factor: Ball Pressure")
abline(h=0)
abline(v=0)
text(fact_ml$loadings,labels=names(data),cex=0.8)
#Correlation matrix analysis
#get reproduced correlation matrix
repro_ml <- fact_ml$loadings%*%t(fact_ml$loadings)
#residual correlation matrix
resid_ml <- cor(data)-repro_ml
#round(resid_ml,2)
#omitted for the sake of succinctness
#get root-mean squared residuals - already provided in output actually
len <- length(resid_ml[upper.tri(resid_ml)])
RMSR_ml <- sqrt(sum(resid_ml[upper.tri(resid_ml)]^2)/len)
#RMSR_ml
#omitted for the sake of succinctness
#get proportion of residuals greater than 0.05 in absolute value
sum(rep(1,len)[abs(resid_ml[upper.tri(resid_ml)])>0.05])/len
#this uses the fa() function in the psych package.  Note that this fails with only 2 factors
fact_paf <- fa(datamat, nfactors = 3, rotate = "varimax", SMC = FALSE, fm="pa")
fact_paf$PVAL
#Loading plot for first two factors Principal Axis Factoring
plot(fact_paf$loadings, pch=18, col='red', main="PAF Loading Plot for First Two Factors",xlab="1st Factor: Ball Control", ylab="2nd Factor: Ball Pressure")
abline(h=0)
abline(v=0)
text(fact_paf$loadings, labels=names(data),cex=0.8)
#Correlation matrix analysis
#get reproduced correlation matrix
repro_paf <- fact_paf$loadings%*%t(fact_paf$loadings)
#residual correlation matrix
resid_paf <- cor(data)-repro_paf
#round(resid_paf,2)
#omitted for the sake of succinctness
#get root-mean squared residuals - already provided in output actually
len <- length(resid_paf[upper.tri(resid_paf)])
RMSR_paf <- sqrt(sum(resid_paf[upper.tri(resid_paf)]^2)/len)
#RMSR_paf
#omitted for the sake of succinctness
#get proportion of residuals greater than 0.05 in absolute value
sum(rep(1,len)[abs(resid_paf[upper.tri(resid_paf)])>0.05])/len
#this uses the fa() function in the psych package.  Note that this fails with only 2 factors
fact_paf <- fa(datamat, nfactors = 3, rotate = "varimax", SMC = FALSE, fm="pa")
fact_paf$PVAL
#Loading plot for first two factors Principal Axis Factoring
plot(fact_paf$loadings, pch=18, col='red', main="PAF Loading Plot for First Two Factors",xlab="1st Factor: Ball Control", ylab="2nd Factor: Ball Pressure")
abline(h=0)
abline(v=0)
text(fact_paf$loadings, labels=names(data),cex=0.8)
#Correlation matrix analysis
#get reproduced correlation matrix
repro_paf <- fact_paf$loadings%*%t(fact_paf$loadings)
#residual correlation matrix
resid_paf <- cor(data)-repro_paf
#round(resid_paf,2)
#omitted for the sake of succinctness
#get root-mean squared residuals - already provided in output actually
len <- length(resid_paf[upper.tri(resid_paf)])
RMSR_paf <- sqrt(sum(resid_paf[upper.tri(resid_paf)]^2)/len)
#RMSR_paf
#omitted for the sake of succinctness
#get proportion of residuals greater than 0.05 in absolute value
sum(rep(1,len)[abs(resid_paf[upper.tri(resid_paf)])>0.05])/len
fact_ml <- fa(datamat, nfactors = 3, SMC = FALSE, rotate = "varimax", fm="ml")
fact_ml$PVAL
#Loading plot for first two factors using Maximum Likelihood
plot(fact_ml$loadings, pch=18, col='red', main="ML Loading Plot for First Two Factors",xlab="1st Factor: Ball Control", ylab="2nd Factor: Ball Pressure")
abline(h=0)
abline(v=0)
text(fact_ml$loadings,labels=names(data),cex=0.8)
#Correlation matrix analysis
#get reproduced correlation matrix
repro_ml <- fact_ml$loadings%*%t(fact_ml$loadings)
#residual correlation matrix
resid_ml <- cor(data)-repro_ml
#round(resid_ml,2)
#omitted for the sake of succinctness
#get root-mean squared residuals - already provided in output actually
len <- length(resid_ml[upper.tri(resid_ml)])
RMSR_ml <- sqrt(sum(resid_ml[upper.tri(resid_ml)]^2)/len)
#RMSR_ml
#omitted for the sake of succinctness
#get proportion of residuals greater than 0.05 in absolute value
sum(rep(1,len)[abs(resid_ml[upper.tri(resid_ml)])>0.05])/len
fact_paf
plot(fact_paf$loadings, pch=18, col='red', main="PAF Loading Plot for First Two Factors",xlab="1st Factor: Ball Control", ylab="2nd Factor: Ball Pressure")
abline(h=0)
abline(v=0)
text(fact_paf$loadings, labels=names(data),cex=0.8)
#Correlation matrix analysis
#get reproduced correlation matrix
repro_paf <- fact_paf$loadings%*%t(fact_paf$loadings)
#residual correlation matrix
resid_paf <- cor(data)-repro_paf
round(resid_paf,2)
fact_paf
#read data
PD <- read.csv("data.csv", header=TRUE, stringsAsFactors = FALSE)
PD <- PD[complete.cases(PD),]
rowNames <- PD[,"Name"]
PD2 <- PD
rowNames <- PD2[,"Name"]
PD[,c("X", "ID", "Name", "Nationality", "Club", "PreferredFoot", "BodyType", "Position", "InternationalReputatiton", "WeakFoot", "SkillMoves")] <- list(NULL)
PD[,7] <- as.numeric(PD[,7])
#sapply(1:ncol(PD), function(a) {class(PD[,a])})
SPD <- scale(PD)
SPD
#get defensive subroup
PDdef <- PD2[ which(PD2$Position == "CB" | PD2$Position == "RCB" | PD2$Position == "LCB" | PD2$Position == "RB" | PD2$Position == "LB" | PD2$Position == "LCB" | PD2$Position == "RCB"), ]
PDdef[,c("X", "ID", "Name", "Nationality", "Club", "PreferredFoot", "BodyType", "Position", "InternationalReputation", "WeakFoot", "SkillMoves")] <- list(NULL)
PDdef[,6] <- as.numeric(PDdef[,6])
SPDdef <- scale (PDdef)
SPDdef
#get midfield subgroup
PDmid <- PD2[ which(PD2$Position == "CM" | PD2$Position == "CDM" | PD2$Position == "CAM" | PD2$Position == "CDM" | PD2$Position == "CAM" | PD2$Position == "LAM" | PD2$Position == "RAM" | PD2$Position == "LCM" | PD2$Position == "RCM" | PD2$Position == "LM" | PD2$Position == "RM"), ]
PDmid[,c("X", "ID", "Name", "Nationality", "Club", "PreferredFoot", "BodyType", "Position", "InternationalReputation", "WeakFoot", "SkillMoves")] <- list(NULL)
PDmid[,6] <- as.numeric(PDmid[,6])
SPDmid <- scale (PDmid)
SPDmid
#get offensive subgroup
PDoff <- PD2[ which(PD2$Position == "ST" | PD2$Position == "RW" | PD2$Position == "RS" | PD2$Position == "LS" | PD2$Position == "LW" | PD2$Position == "RW" | PD2$Position == "CF" | PD2$Position == "LF" | PD2$Position == "RF"), ]
PDoff[,c("X", "ID", "Name", "Nationality", "Club", "PreferredFoot", "BodyType", "Position", "InternationalReputation", "WeakFoot", "SkillMoves")] <- list(NULL)
PDoff[,6] <- as.numeric(PDoff[,6])
SPDoff <- scale (PDoff)
SPDoff
fviz_nbclust(SPDoff, kmeans, method = "silhouette") +
labs(title= "Optimal Cluster Number for Strikers - Silhouette Method")
fviz_nbclust(SPDoff, kmeans, method = "wss") +
labs(title= "Optimal Cluster Number for Strikers - WSS Method") +
geom_vline(xintercept = 3 , linetype = 2)
nboff <- NbClust(SPDoff, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "complete", index ="all")
offk2 <- kmeans(SPDoff, centers = 2)
offk3 <- kmeans(SPDoff, centers = 3)
offk4 <- kmeans(SPDoff, centers = 4)
offk5 <- kmeans(SPDoff, centers = 5)
offp2 <- fviz_cluster(offk2, geom = "point", data = SPDoff) +
ggtitle("k = 2")
offp3 <- fviz_cluster(offk3, geom = "point",  data = SPDoff) +
ggtitle("k = 3")
offp4 <- fviz_cluster(offk4, geom = "point",  data = SPDoff) +
ggtitle("k = 4")
offp5 <- fviz_cluster(offk5, geom = "point",  data = SPDoff) +
ggtitle("k = 5")
marrangeGrob(grobs=list(offp2, offp3, offp4, offp5), ncol=2, nrow = 2)
fviz_nbclust(SPDdef, kmeans, method = "silhouette") +
labs(title= "Optimal Cluster Number for Center Backs - Silhouette Method")
fviz_nbclust(SPDdef, kmeans, method = "wss") +
labs(title= "Optimal Cluster Number for Center Backs - WSS Method") +
geom_vline(xintercept = 3 , linetype = 2)
nboff <- NbClust(SPDoff, distance = "euclidean", min.nc = 2,
max.nc = 10, method = "complete", index ="all")
quit()
